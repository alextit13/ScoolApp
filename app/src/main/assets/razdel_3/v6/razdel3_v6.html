<!DOCTYPE html>
<!-- Template by quackit.com -->
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>v6</title>
	<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
	
</head>
	<style>
		body {
            background-image:url(file:///android_res/drawable/pict.jpg);
			color: aliceblue;
		}
	</style>

	<body>
<p style="text-indent:25px;">Рассмотрим управляемую систему, в которой ОУ находится в состоянии \(Y\), а СУ в состоянии \(Х\). Тогда:<br>
   \(I(Х, Y) = H(Х) - H(Х/Y)\), где \(H(Х)\) – энтропия системы управления, а \(H(Х/Y)\) – энтропия СУ после управляющего воздействия на объект управления, находящийся в состоянии \(Y\). 
   В силу симметричности информации предыдущего можно переписать в виде:<br>
   \(I(Х, Y) = I (Y, Х) = H(Y) - H(Y/Х)\) при наличии идеальных каналов связи. Тогда:\(H(Х) - H(Х/Y) = H(Y) - H(Y/Х)\). Поэтому: \(H(Y/Х) = H(Y) - H(Х) + H(Х/Y)\).
 
</p>

<p style="text-indent:25px;">Энтропия ОУ при получении им управляющего воздействия \(Х\) со стороны СУ должна стремиться к нулю \(H(Y/Х) \to 0\) и энтропия СУ тоже должна стремиться к нулю \(H(Х/Y) \to 0\). 
Отсюда вытекает, что энтропии СУ и ОУ должны в идеальном случае совпадать! Таким образом, разнообразие ОУ и его соответствующего СУ должны находиться в определенном соотношении. Эта связь была обнаружена кибернетиком У.Россом Эшби и формулируется так: 
«Разнообразие управляющей системы должно быть не меньше разнообразия управляемого объекта».
 
</p>

<p style="text-indent:25px;">Согласно этому принципу при увеличении сложности ОУ должна увеличиваться и сложность СУ. Этот принцип называется принципом необходимого разнообразия, и из него следует, что «нужно стремиться к тому, чтобы на каждое возможное состояние управляемого 
объекта имелось свое управляющее воздействие».
</p>

<p style="text-indent:25px;">В теории информации мерой разнообразия состояния объекта служит «энтропия». Это понятие связано с мерой количества информации. Если состояние объекта характеризуется одним показателем \(y\), принимающим значения \(y_1, y_2,…, y_n\), то сообщение \(Y\) о том, 
что объект находится в одном из этих состояний, будет содержать количество информации, равное его энтропии: \(H(Y)= - \sum_{i=1,n} p(y_i) \log_2 {p(y_i)}\), где \(p(y_i)\) – вероятность того, что объект может находиться в состоянии \(y_i\), при этом очевидно \(\sum_{i=1,n} p(y_i)=1\).
</p>


<p style="text-indent:25px;"><strong>Использованная литература:</strong></p>
1) А.Н. Бугров, В.Н. Добрынин. Основы теории управления: учебное пособие. – Дубна: Международный университет природы, общества и человека «Дубна», 2004

</body>
</html>